{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://europe-west1-atp-views-tracker.cloudfunctions.net/working-analytics?notebook=tutorials--agent-with-tavily-web-access--search-extract-crawl)\n",
    "\n",
    "# 1. Search, Extract, and Crawl the Web üåê\n",
    "\n",
    "Welcome! In this tutorial, you'll gain hands-on experience with the core capabilities of the Tavily API‚Äîsearching the web with semantic understanding, extracting content from live web pages, and crawling entire websites. \n",
    "\n",
    "These skills are essential for anyone building AI agents or applications that need up-to-date, relevant information from the internet. By learning how to programmatically access and process real-time web data, you'll be able to bridge the gap between static language models and the dynamic world they operate in, making your agents smarter, more accurate, and context-aware.\n",
    "\n",
    "We'll cover:\n",
    "- How to perform web searches and retrieve the most relevant results\n",
    "- How to extract clean, usable content from any URL\n",
    "- How to crawl websites to gather comprehensive information\n",
    "- How to fine-tune your queries with advanced parameters\n",
    " \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Follow these steps to set up:\n",
    "\n",
    "1. **Sign up** for Tavily at [app.tavily.com](https://app.tavily.com/home/?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant) to get your API key.\n",
    "\n",
    "   *Refer to the screenshots linked below for step-by-step guidance:*\n",
    "\n",
    "   - ![Screenshot: Signup Page](assets/sign-up.png)\n",
    "   - ![Screenshot: Tavily API Keys Dashboard](assets/api-key.png)\n",
    "\n",
    "\n",
    "2. **Copy your API key** from your Tavily account dashboard.\n",
    "\n",
    "3. **Paste your API key** into the cell below and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export your API key into a .env file, run the following cell (replace with your actual keys):\n",
    "!echo \"TAVILY_API_KEY=<your-tavily-api-key>\" >> .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade tavily-python --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68451e3b",
   "metadata": {},
   "source": [
    "### Setting Up Your Tavily API Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will instantiate the Tavily client with your API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Prompt the user to securely input the API key if not already set in the environment\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY:\\n\")\n",
    "\n",
    "# Initialize the Tavily API client using the loaded or provided API key\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search üîç \n",
    "\n",
    "Let's run a basic web search query to retrieve up-to-date information about NYC. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a web search to retrieve the most up-to-date information available.\n",
    "search_results = tavily_client.search(\n",
    "    query=\"What happened in NYC today?\", max_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This search invocation will return 5 results. Each result includes the web page's title, URL, a content snippet for RAG purposes, and a semantic score indicating how closely the result matches your query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for result in search_results[\"results\"]:\n",
    "    print(result[\"title\"])\n",
    "    print(result[\"url\"])\n",
    "    print(result[\"content\"])\n",
    "    print(result[\"score\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment with different API parameter configurations to see Tavily in action. Try everything from broad topics to specific questions! You can adjust parameters such as the number of results, time range, and domain filters to tailor your search. For more information, read the search [API reference](https://docs.tavily.com/documentation/api-reference/endpoint/search?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant) and [best practices guide](https://docs.tavily.com/documentation/best-practices/best-practices-search?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant). Let's apply a time range filter, domain filter, and use the `news` search topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a web search with a specific time range, domain filter, and topic filter.\n",
    "search_results = tavily_client.search(\n",
    "    query=\"Anthropic model release?\",\n",
    "    max_results=5,\n",
    "    time_range=\"month\",\n",
    "    include_domains=[\"techcrunch.com\"],\n",
    "    topic=\"news\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all the results are from `techcrunch.com` and are limited to the past month. By setting the `news` topic, our search is focused on trusted third-party news sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for result in search_results[\"results\"]:\n",
    "    print(result[\"title\"])\n",
    "    print(result[\"url\"])\n",
    "    print(result[\"content\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract üìÑ \n",
    "\n",
    "Next, we'll use the Tavily extract endpoint to retrieve the complete content (i.e., `raw_content`) of each page using the URLs from our previous search results. Instead of just using the short content snippets from the search, this allows us to access the full text of each page. For efficiency, the extract endpoint can process up to 20 URLs at once in a single call. For more information, read the extract [API reference](https://docs.tavily.com/documentation/api-reference/endpoint/extract?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant) and [best practices guide](https://docs.tavily.com/documentation/best-practices/best-practices-extract?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the full-page content from the URLs in the search results.\n",
    "extract_results = tavily_client.extract(\n",
    "    urls=[result[\"url\"] for result in search_results[\"results\"]],\n",
    "    # extract_depth=\"advanced\", #uncomment to use our advanced extract depth for complex web pages with dynamic content, embedded media, or structured data.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the raw content, which provides much more detailed and complete information than the short content snippets shown earlier. If you use raw content as input to LLMs, remember to consider your model's context window limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for result in extract_results[\"results\"]:\n",
    "    print(result[\"url\"])\n",
    "    print(result[\"raw_content\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than using the Extract endpoint to return raw page content, we can combine the search and extract endpoints into a API call by using the search endpoint with the `include_raw_content=True` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a web search with live content extraction.\n",
    "search_results = tavily_client.search(\n",
    "    query=\"Anthropic model release?\",\n",
    "    max_results=1,\n",
    "    include_raw_content=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each search result now contains the web page's title, URL, semantic score, a content snippet, and the complete raw content. Tavily's flexible and modular API supports building a wide range of agentic systems, regardless of model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for result in search_results[\"results\"]:\n",
    "    print(result[\"url\"])\n",
    "    print(result[\"content\"])\n",
    "    print(result[\"score\"])\n",
    "    print(result[\"raw_content\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl üï∏Ô∏è \n",
    "\n",
    "Now let‚Äôs use Tavily to crawl a webpage and extract all its links. Web crawling is the process of automatically navigating through websites by following hyperlinks to discover numerous web pages and URLs (think of it like falling down a Wikipedia rabbit hole üêá‚Äîclicking from page to page, diving deeper into interconnected topics). For autonomous web agents, this capability is essential for accessing deep web data which might be difficult to retrieve via search. For more information, read the crawl [API reference](https://docs.tavily.com/documentation/api-reference/endpoint/crawl?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant) and [best practices guide](https://docs.tavily.com/documentation/best-practices/best-practices-crawl?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by crawling the Tavily website to gather all nested pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawl the Tavily website\n",
    "crawl_results = tavily_client.crawl(url=\"tavily.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see all the nested URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for result in crawl_results[\"results\"]:\n",
    "    print(result[\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crawl endpoint also returns the raw page content of each URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for result in crawl_results[\"results\"]:\n",
    "    print(result[\"url\"])\n",
    "    print(result[\"raw_content\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested in just the links (without the full page content), use the Map endpoint. It's a faster and more cost-effective way to retrieve all the links from a site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the Tavily website\n",
    "map_results = tavily_client.map(url=\"tavily.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the results, which only contain the links in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `instructions` parameter of the crawl/map endpoint is a powerful feature that lets you guide the web crawl using natural language instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the Tavily website with natural language instructions\n",
    "guided_map_results = tavily_client.map(\n",
    "    url=\"tavily.com\", instructions=\"find only the developer docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the results will only include developer docs from the Tavily webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different URLs to see how Tavily maps the structure of different websites. How would you integrate this into your agentic systems...ü§î?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps\n",
    " \n",
    "In this tutorial, you learned how to:\n",
    "- Perform real-time web searches using the Tavily API\n",
    "- Extract content from web pages\n",
    "- Crawl and map websites to gather links and information\n",
    "- Guide crawls with natural language instructions for targeted data extraction\n",
    " \n",
    "These foundational skills enable your agents to access and utilize up-to-date web information, making them more powerful and context-aware. Feel free to experiment with the Tavily API in the [playground](https://app.tavily.com/playground?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant) and read the [best practices guide](https://docs.tavily.com/documentation/best-practices/best-practices-search?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant) to optimize for your use case.\n",
    " \n",
    "**Ready to take the next step?**  \n",
    "In **Tutorial #2: Building a Web Agent** that can search, extract, and crawl autonomously, you'll combine these capabilities to build a fully autonomous web agent. This agent will be able to reason, decide when to search, crawl, or extract, and integrate web data into its workflow‚Äîall powered by Tavily.\n",
    " \n",
    "[üëâ **Continue to Tutorial #2!**](./web-agent-tutorial.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
