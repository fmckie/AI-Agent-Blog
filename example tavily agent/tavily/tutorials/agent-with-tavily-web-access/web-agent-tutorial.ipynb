{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://europe-west1-atp-views-tracker.cloudfunctions.net/working-analytics?notebook=tutorials--agent-with-tavily-web-access--web-agent-tutorial)\n",
    "\n",
    "# 2. Build a Web Research Agent ðŸ§™ \n",
    "\n",
    "Welcome to tutorial 2!\n",
    "\n",
    "In the first exercise, you learned the basics of the \n",
    "Tavily API. Now, let's take it a step further: we'll \n",
    "combine that knowledge with LLMs to unlock \n",
    "real value. In this tutorial, you'll learn how to build a web research agent that can search, extract, crawl, and reason over live web data.\n",
    "\n",
    "You already explored the various parameter \n",
    "configurations available for each Tavily API endpoint. \n",
    "With the official [Tavily-LangChain integration](https://www.tavily.com/integrations/langchain) integration, our agent can \n",
    "automatically set these parametersâ€”like the \n",
    "`time_range` for search or specific crawl \n",
    "`instructions`â€”based on the context and requirements of \n",
    "each task. This dynamic, LLM-powered configuration is \n",
    "powerful in agentic systems.\n",
    "\n",
    "By the end of this lesson, you'll know how to:\n",
    "- Seamlessly connect foundation models to the web for up-to-date research\n",
    "- Build a react-style web agent \n",
    "- Dynamically configure search, extract, and crawl parameters the Tavily-LangChain integration.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Follow these steps to set up:\n",
    "\n",
    "1. **Sign up** for Tavily at [app.tavily.com](https://app.tavily.com/home/?utm_source=github&utm_medium=referral&utm_campaign=nir_diamant) to get your API key.\n",
    "\n",
    "   *Refer to the screenshots linked below for step-by-step guidance:*\n",
    "\n",
    "   - ![Screenshot: Signup Page](assets/sign-up.png)\n",
    "   - ![Screenshot: Tavily API Keys Dashboard](assets/api-key.png)\n",
    "\n",
    "\n",
    "2. **Sign up** for OpenAI to get your API key. By default, weâ€™ll use OpenAIâ€”but you can substitute any other LLM provider.\n",
    "   \n",
    "\n",
    "2. **Copy your API keys** from your Tavily and OpenAI account dashboard.\n",
    "\n",
    "3. **Paste your API keys** into the cell below and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export your API keys into a .env file, run the following cell (replace with your actual keys):\n",
    "!echo \"TAVILY_API_KEY=<your-tavily-api-key>\" >> .env\n",
    "!echo \"OPENAI_API_KEY=<your-openai-api-key>\" >> .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U tavily-python langchain-openai langchain langchain-tavily langgraph --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Your Tavily API Client\n",
    "\n",
    "The code below will instantiate the Tavily client with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Prompt the user to securely input the API key if not already set in the environment\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY:\\n\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "# Initialize the Tavily API client using the loaded or provided API key\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the following modular tools with the Tavily-LangChain integration:\n",
    "1. **Search** the web for relevant information\n",
    "\n",
    "2. **Extract** content from specific web pages\n",
    "\n",
    "3. **Crawl** entire websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set of web tools our agent will use to interact with the Tavily API.\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_tavily import TavilyExtract\n",
    "from langchain_tavily import TavilyCrawl\n",
    "\n",
    "# Define the LangChain search tool\n",
    "search = TavilySearch(max_results=10, topic=\"general\")\n",
    "\n",
    "# Define the LangChain extract tool\n",
    "extract = TavilyExtract(extract_depth=\"advanced\")\n",
    "\n",
    "# Define the LangChain crawl tool\n",
    "crawl = TavilyCrawl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up several OpenAI foundation models to power our agent, such as o3-mini and the gpt-4.1 model. If you prefer a different LLM provider, you can easily plug in any LangChain Chat Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the OpenAI foundation models\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# o3-mini-2025-01-31\n",
    "o3_mini = ChatOpenAI(model=\"o3-mini-2025-01-31\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# gpt-4.1\n",
    "gpt_4_1 = ChatOpenAI(model=\"gpt-4.1\", api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Agent\n",
    "\n",
    "Next, we'll build a Web Agent powered by Tavily, which consists of three main components: the language model, a set of web tools, and a system prompt. The language model (such as o3-mini or gpt-4.1) serves as the agent's \"brain,\" while the web tools (Search, Extract, and Crawl) allow the agent to interact with and gather information from the internet. The system prompt guides the agent's behavior, explaining how and when to use each tool to accomplish its research goals.\n",
    "\n",
    "This agent leverages a pre-built LangGraph reAct implementation, as illustrated in the diagram below. The reAct framework enables the agent to reason about which actions to take, use the web tools in sequence, and iterate as needed until it completes its research task. The system prompt is especially importantâ€”it instructs the agent on best practices for using the tools together, ensuring that the agent's responses are thorough, accurate, and well-sourced.\n",
    "\n",
    "You are encouraged to experiment with the system prompt or try different language models (like swapping between gpt-4.1 and o3-mini) to change the agent's style, personality, or optimize its performance for specific use cases.\n",
    "\n",
    "<img src=\"./assets/web-agent.svg\" alt=\"Agent\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "today = datetime.datetime.today().strftime(\"%A, %B %d, %Y\")\n",
    "\n",
    "# Create the web agent\n",
    "web_agent = create_react_agent(\n",
    "    model=gpt_4_1,\n",
    "    tools=[search, extract, crawl],\n",
    "    prompt=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                f\"\"\"    \n",
    "        You are a research agent equipped with advanced web tools: Tavily Web Search, Web Crawl, and Web Extract. Your mission is to conduct comprehensive, accurate, and up-to-date research, grounding your findings in credible web sources.\n",
    "\n",
    "        **Today's Date:** {today}\n",
    "\n",
    "        **Available Tools:**\n",
    "\n",
    "        1. **Tavily Web Search**\n",
    "\n",
    "        * **Purpose:** Retrieve relevant web pages based on a query.\n",
    "        * **Usage:** Provide a search query to receive semantically ranked results, each containing the title, URL, and a content snippet.\n",
    "        * **Best Practices:**\n",
    "\n",
    "            * Use specific queries to narrow down results.\n",
    "            * Optimize searches using parameters such as `search_depth`, `time_range`, `include_domains`, and `include_raw_content`.\n",
    "            * Break down complex queries into specific, focused sub-queries.\n",
    "\n",
    "        2. **Tavily Web Crawl**\n",
    "\n",
    "        * **Purpose:** Explore a website's structure and gather content from linked pages for deep research and information discovery from a single source.\n",
    "        * **Usage:** Input a base URL to crawl, specifying parameters such as `max_depth`, `max_breadth`, and `extract_depth`.\n",
    "        * **Best Practices:**\n",
    "\n",
    "            * Begin with shallow crawls and progressively increase depth.\n",
    "            * Utilize `select_paths` or `exclude_paths` to focus the crawl.\n",
    "            * Set `extract_depth` to \"advanced\" for comprehensive extraction.\n",
    "\n",
    "        3. **Tavily Web Extract**\n",
    "\n",
    "        * **Purpose:** Extract the full content from specific web pages.\n",
    "        * **Usage:** Provide URLs to retrieve detailed content.\n",
    "        * **Best Practices:**\n",
    "\n",
    "            * Set `extract_depth` to \"advanced\" for detailed content, including tables and embedded media.\n",
    "            * Enable `include_images` if image data is necessary.\n",
    "\n",
    "        **Guidelines for Conducting Research:**\n",
    "\n",
    "        * **Citations:** Always support findings with source URLs, clearly provided as in-text citations.\n",
    "        * **Accuracy:** Rely solely on data obtained via provided toolsâ€”never fabricate information.\n",
    "        * **Methodology:** Follow a structured approach:\n",
    "\n",
    "        * **Thought:** Consider necessary information and next steps.\n",
    "        * **Action:** Select and execute appropriate tools.\n",
    "        * **Observation:** Analyze obtained results.\n",
    "        * Repeat Thought/Action/Observation cycles as needed.\n",
    "        * **Final Answer:** Synthesize and present findings with citations in markdown format.\n",
    "\n",
    "        **Example Workflows:**\n",
    "\n",
    "        **Workflow 1: Search Only**\n",
    "\n",
    "        **Question:** What are recent news headlines about artificial intelligence?\n",
    "\n",
    "        * **Thought:** I need quick, recent articles about AI.\n",
    "        * **Action:** Use Tavily Web Search with the query \"recent artificial intelligence news\" and set `time_range` to \"week\".\n",
    "        * **Observation:** Retrieved 10 relevant articles from reputable news sources.\n",
    "        * **Final Answer:** Summarize key headlines with citations.\n",
    "\n",
    "        **Workflow 2: Search and Extract**\n",
    "\n",
    "        **Question:** Provide detailed insights into recent advancements in quantum computing.\n",
    "\n",
    "        * **Thought:** I should find recent detailed articles first.\n",
    "        * **Action:** Use Tavily Web Search with the query \"recent advancements in quantum computing\" and set `time_range` to \"month\".\n",
    "        * **Observation:** Retrieved 10 relevant results.\n",
    "        * **Thought:** I should extract content from the most comprehensive article.\n",
    "        * **Action:** Use Tavily Web Extract on the most relevant URL from search results.\n",
    "        * **Observation:** Extracted detailed information about quantum computing advancements.\n",
    "        * **Final Answer:** Provide detailed insights summarized from extracted content with citations.\n",
    "\n",
    "        **Workflow 3: Search and Crawl**\n",
    "\n",
    "        **Question:** What are the latest advancements in renewable energy technologies?\n",
    "\n",
    "        * **Thought:** I need recent articles about advancements in renewable energy.\n",
    "        * **Action:** Use Tavily Web Search with the query \"latest advancements in renewable energy technologies\" and set `time_range` to \"month\".\n",
    "        * **Observation:** Retrieved 10 articles discussing recent developments in solar panels, wind turbines, and energy storage.\n",
    "        * **Thought:** To gain deeper insights, I'll crawl a relevant industry-leading renewable energy site.\n",
    "        * **Action:** Use Tavily Web Crawl on the URL of a leading renewable energy industry website, setting `max_depth` to 2.\n",
    "        * **Observation:** Gathered extensive content from multiple articles linked on the site, highlighting new technologies and innovations.\n",
    "        * **Final Answer:** Provide a synthesized summary of findings with citations.\n",
    "\n",
    "        ---\n",
    "\n",
    "        You will now receive a research question from the user:\n",
    "\n",
    "        \"\"\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"web_agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Tavily Web Agent\n",
    "\n",
    "Now we'll run the agent and see how it uses the different web tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Test the web agent\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"find all the iphone models currently available on apple.com and their prices\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Stream the web agent's response\n",
    "for s in web_agent.stream(inputs, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the agent's intermediate steps printed above, including how it chooses and configures different tool parameters. Then, display the agent's final answer in markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a different example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the web agent\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"return 5 job postings for a software engineer in the bay area on linkedin\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Stream the web agent's response\n",
    "for s in web_agent.stream(inputs, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the agent's final response as markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the agent's final response as markdown\n",
    "Markdown(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the agent cleverly combines Tavilyâ€™s toolsâ€”search, crawl, and extractâ€”to complete the task end-to-end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps\n",
    " \n",
    "In this tutorial, you learned how to:\n",
    "- Set up Tavily web tools (search, extract, crawl) with LangChain\n",
    "- Build an intelligent web research agent using LangGraph's `create_react_agent`\n",
    "- Design effective system prompts for autonomous web research\n",
    "- Test your agent with real-world tasks like product research and job searching\n",
    " \n",
    "You now have a fully functional web research agent that autonomously combines search, extraction, and crawling to complete complex research objectives.\n",
    " \n",
    "**Ready for more advanced capabilities?**  \n",
    "Continue to **Tutorial #3: Building a Hybrid Agent** to learn how to integrate web research with internal vector search. You'll unlock new capabilities for any scenario where both internal and external knowledge matter.\n",
    " \n",
    "[ðŸ‘‰ **Continue to Tutorial #3**](./hybrid-agent-tutorial.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
